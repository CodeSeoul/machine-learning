{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Intro to PyTorch Hooks - Solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import typing as t\n",
    "\n",
    "# Mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Default network for testing\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(10, 20)\n",
    "        self.fc_2 = nn.Linear(20, 30)\n",
    "        self.fc_3 = nn.Linear(30, 2)\n",
    "        self.relu = lambda x: F.relu(x)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        first_output = self.fc_1(input_tensor)\n",
    "        second_output = self.fc_2(first_output)\n",
    "        third_output = self.fc_3(second_output)\n",
    "        final_output = self.relu(third_output)\n",
    "        return final_output\n",
    "\n",
    "    \n",
    "def get_pyplot_figure_for_batch(output_array: torch.Tensor) -> plt.figure:\n",
    "    \"\"\"\n",
    "    Just use this to visualize the output of each layer\n",
    "    \"\"\"\n",
    "    # Get the shape of the output tensor\n",
    "    output_shape = output_array.shape    \n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    for i in range(output_shape[2]):\n",
    "        ax = fig.add_subplot(output_shape[2]//8 + 1, 8, i+1)\n",
    "        if output_shape[2] == 1: # If only one channel, skip the last axis\n",
    "            ax.imshow(output_array[:,:,0], cmap='gray', interpolation='nearest')\n",
    "            ax.imshow(np.dstack((output_array[:,:,0], output_array[:,:,0], output_array[:,:,0])))\n",
    "        else:\n",
    "            ax.imshow(output_array[:,:,i], cmap='jet', interpolation='nearest')\n",
    "            ax.imshow(np.dstack((output_array[:,:,i], output_array[:,:,i], output_array[:,:,i])))\n",
    "        ax.axis('off')\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "Given the `LinearModel` in the earlier section, using the PyTorch forward pre-hook.\n",
    "\n",
    "1. Define an instance of `LinearModel`\n",
    "2. Add a forward pre_hook to `fc_1` and `fc_3` that prints out the original input and the tensor shape.\n",
    "3. Afterwards, try passing in a random tensor created using `torch.randn` or your function of choice and check whether the hook is working as intended.\n",
    "4. Lastly, try removing the hook attached to `fc_3`. \n",
    "5. Afterwards, try passing in a random tensor created using `torch.randn` or your function of choice and check whether the hook to `fc_3` has been successfully removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tuple shape: torch.Size([3, 10]), Tensor: torch.Size([3, 10])\n",
      "Input tuple shape: torch.Size([3, 30]), Tensor: torch.Size([3, 30])\n",
      "Forward pass completed --------------\n",
      "Input tuple shape: torch.Size([3, 10]), Tensor: torch.Size([3, 10])\n",
      "Forward pass completed --------------\n"
     ]
    }
   ],
   "source": [
    "# Solution \n",
    "# -----------------------------------\n",
    "\n",
    "# Step 1\n",
    "model = LinearModel()\n",
    "\n",
    "\n",
    "# Step 2. Define the hook function\n",
    "def forward_prehook(module: nn.Module, input_tuple: t.Tuple[torch.Tensor, ...]) -> None:\n",
    "    # A better solution would be to iterate over the tuple and print, but oh well\n",
    "    print(f'Input tuple shape: {input_tuple[0].shape}, Tensor: {input_tuple[0].shape}')\n",
    "\n",
    "# Add the hooks\n",
    "fc1_prehook_handle = model.fc_1.register_forward_pre_hook(forward_prehook)\n",
    "fc3_prehook_handle = model.fc_3.register_forward_pre_hook(forward_prehook)\n",
    "\n",
    "# 3. Pass in a random tensor\n",
    "batch_size = 3\n",
    "input_size = 10\n",
    "random_tensor = torch.randn(batch_size, input_size)\n",
    "\n",
    "# Forward pass\n",
    "output = model(random_tensor)\n",
    "print('Forward pass completed --------------')\n",
    "\n",
    "# 4. Remove fc_3 hook\n",
    "fc3_prehook_handle.remove()\n",
    "\n",
    "# 5. Forward pass again\n",
    "output = model(random_tensor)\n",
    "print('Forward pass completed --------------') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.2 \n",
    "\n",
    "Right now, there is no way to add hooks onto the relu activation, because the `ReLU` activation is not implemented. \n",
    "The goal of this exercise is to\n",
    "\n",
    "1. Try adding a forward pre-hook to the ReLU operation. It should fail.\n",
    "2. Update the neural network so that we can add the forward pre-hook to the `ReLU` operation in the neural network above.\n",
    "3. Create a random input tensor\n",
    "4. Feed that random input tensor to the neural network and print the outputs\n",
    "5. Add a forward pre-hook to the `ReLU` layer.\n",
    "6. Feed the random input tensor from step 2 and check whether ReLU hook is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: --------------\n",
      "'function' object has no attribute 'register_forward_pre_hook'\n",
      "--------------------------------------------------\n",
      "tensor([[0.0000, 0.0285],\n",
      "        [0.1571, 0.1778],\n",
      "        [0.1387, 0.2557]], grad_fn=<ReluBackward0>)\n",
      "it is working!!!! (tensor([[-0.1663,  0.0285],\n",
      "        [ 0.1571,  0.1778],\n",
      "        [ 0.1387,  0.2557]], grad_fn=<AddmmBackward0>),)\n",
      "tensor([[0.0000, 0.0285],\n",
      "        [0.1571, 0.1778],\n",
      "        [0.1387, 0.2557]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Solution Exercise 1.2 here \n",
    "# -----------------------------------\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(10, 20)\n",
    "        self.fc_2 = nn.Linear(20, 30)\n",
    "        self.fc_3 = nn.Linear(30, 2)\n",
    "        self.relu = lambda x: F.relu(x)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        first_output = self.fc_1(input_tensor)\n",
    "        second_output = self.fc_2(first_output)\n",
    "        third_output = self.fc_3(second_output)\n",
    "        final_output = self.relu(third_output)\n",
    "        return final_output\n",
    "\n",
    "def relu_pre_hook(module, input_tensors: t.Tuple[torch.Tensor, ...]) -> t.Tuple[torch.Tensor, ...]:\n",
    "    print(f'it is working!!!! {input_tensors}')\n",
    "\n",
    "model = LinearModel()\n",
    "try:\n",
    "    # This should fail\n",
    "    model.relu.register_forward_pre_hook(relu_pre_hook)\n",
    "except AttributeError as e:\n",
    "    print('Error: --------------')\n",
    "    print(e)\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 1. Updated neural network\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(10, 20)\n",
    "        self.fc_2 = nn.Linear(20, 30)\n",
    "        self.fc_3 = nn.Linear(30, 2)\n",
    "        # Convert relu to a nn.Module\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        first_output = self.fc_1(input_tensor)\n",
    "        second_output = self.fc_2(first_output)\n",
    "        third_output = self.fc_3(second_output)\n",
    "        final_output = self.relu(third_output)\n",
    "        return final_output\n",
    "\n",
    "\n",
    "model = LinearModel()\n",
    "\n",
    "# 2. Create random input tensor\n",
    "batch_size = 3\n",
    "input_size = 10\n",
    "random_tensor = torch.randn(batch_size, input_size)\n",
    "\n",
    "# 3. Feed the random input tensor to Neural network\n",
    "output = model(random_tensor)\n",
    "print(output)\n",
    "\n",
    "# 4. Add forward pre-hook to ReLU()\n",
    "model.relu.register_forward_pre_hook(relu_pre_hook)\n",
    "\n",
    "output = model(random_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Perform the following steps\n",
    "\n",
    "1. Try adding a foward_hook to the relu layer. It should double the output of the ReLU activation.\n",
    "2. Log and verify the results\n",
    "3. Afterwards remove the hook and do a forward pass to ensure that it is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.2667],\n",
      "        [0.2076, 0.2881],\n",
      "        [0.3127, 0.4713]], grad_fn=<ReluBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tensor([[0.0000, 0.5334],\n",
      "        [0.4152, 0.5761],\n",
      "        [0.6253, 0.9426]], grad_fn=<MulBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I should be restored to normal\n",
      "tensor([[0.0000, 0.2667],\n",
      "        [0.2076, 0.2881],\n",
      "        [0.3127, 0.4713]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# -----------------------------------\n",
    "\n",
    "model = LinearModel()\n",
    "batch_size = 3\n",
    "input_size = 10\n",
    "random_tensor = torch.randn(batch_size, input_size)\n",
    "\n",
    "# Before double\n",
    "output = model(random_tensor)\n",
    "print(output)\n",
    "\n",
    "# 1. double output\n",
    "def double_relu(module: nn.Module, \n",
    "                inputs: torch.Tensor, \n",
    "                outputs: torch.Tensor) -> torch.Tensor:\n",
    "    return output * 2\n",
    "\n",
    "\n",
    "relu_forward_hook = model.relu.register_forward_hook(double_relu)\n",
    "\n",
    "# 2. Log and verify results\n",
    "print('-' * 100)\n",
    "output = model(random_tensor)\n",
    "print(output)\n",
    "\n",
    "# 3. Remove hook and do forward pass\n",
    "relu_forward_hook.remove()\n",
    "print('-' * 100)\n",
    "print('I should be restored to normal')\n",
    "output = model(random_tensor)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "The goal is to perform the following steps.\n",
    "\n",
    "1. Analyze the `resnet18` 's modules. \n",
    "   1. Try looking at `.modules()`\n",
    "2. After asssessing the network structure and module names, find a way to filter out all the modules that output convolutional feature maps\n",
    "3. Add a forward hook to each of these convolutional modules so that we\n",
    "   1. Visualize the first `four` convolutional layers using `matplotlib`\n",
    "4. Feed the dog image into the neural network. You can also feel free to grab other images from the internet to test with.\n",
    "5. Lastly, remove all the hooks registered to the neural network\n",
    "6. Try feeding the dog image again to check that the forward hooks have properly been detached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaylee/machine-learning/230408_pytorch_hooks/pytorch_hooks/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jaylee/machine-learning/230408_pytorch_hooks/pytorch_hooks/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# The starter code is copied from \n",
    "# https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/\n",
    "# Please do not look at the sample code above before attempting this exercise and only \n",
    "# refer to it if you have are stuck\n",
    "\n",
    "# input (single)\n",
    "image = Image.open('puppy.jpg')\n",
    "transform = T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
    "input_image = transform(image).unsqueeze(dim=0)\n",
    "\n",
    "# original model\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Solution for 2.2 - \n",
    "# it is very similar to the exercise in the given example, so skip if it you are running out of time\n",
    "# TODO: When you have time, write out solutions\n",
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "\n",
    "One very useful technique when training neural networks is a technique called \"Gradient Clipping\". \n",
    "It is a very useful techique to prevent exploding gradients when training neural networks. \n",
    "Exploding gradients are a very common issue when training Recurrent neural network, due to the \n",
    "backpropagation through time technique. \n",
    "\n",
    "An example of Gradient clipping is something like the following:\n",
    "\n",
    "\"If the gradient becomes greater than 10, set it to 10\".\n",
    "\n",
    "Gradient clipping can be implemented using PyTorch backward hooks (there is also a function for it, but assume that it doesn't exist). \n",
    "\n",
    "Your goal is to implement gradient clipping in the exercise and to check the gradient values to ensure that it is working correctly. \n",
    "Use the previous network (`resnet18`) from the previous exercise and try feeding the dog image.\n",
    "\n",
    "1. Write a backward hook that clips gradients that are greater than `gradient_threshold` where, the value `gradient_threshold` is a variable. Feel free to use either ResNet18 or a simple model of your choice.\n",
    "2. Visualize the gradient via printing onto the console\n",
    "   1. If you are feeling adventurous, try logging the results onto TensorBoard (not that difficult)\n",
    "3. Check the gradients to ensure that the gradients are being properly clipped. \n",
    "   1. Try setting the threshold to various values and experiment with your implementation.\n",
    "\n",
    "Leverage the given neural network and model to work with the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: ouput_shape: torch.Size([20])\n",
      "Forward: ouput_shape: torch.Size([30])\n",
      "Forward: ouput_shape: torch.Size([2])\n",
      "Backward input gradient -- shape: torch.Size([2])\n",
      "Backward input gradient -- shape: torch.Size([10, 30])\n",
      "Backward input gradient -- shape: torch.Size([30, 2])\n",
      "Backward output gradient -- shape: torch.Size([10, 2])\n",
      "Backward input gradient -- shape: torch.Size([30])\n",
      "Backward input gradient -- shape: torch.Size([10, 20])\n",
      "Backward input gradient -- shape: torch.Size([20, 30])\n",
      "Backward output gradient -- shape: torch.Size([10, 30])\n",
      "Backward input gradient -- shape: torch.Size([20])\n",
      "Backward input gradient -- Not a leaf node. Only leaf nodes accumulate gradients\n",
      "Backward input gradient -- shape: torch.Size([10, 20])\n",
      "Backward output gradient -- shape: torch.Size([10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaylee/machine-learning/230408_pytorch_hooks/pytorch_hooks/lib/python3.11/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Default network for testing\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(10, 20)\n",
    "        self.fc_2 = nn.Linear(20, 30)\n",
    "        self.fc_3 = nn.Linear(30, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        first_output = self.fc_1(input_tensor)\n",
    "        second_output = self.fc_2(first_output)\n",
    "        third_output = self.fc_3(second_output)\n",
    "        final_output = self.relu(third_output)\n",
    "        return final_output\n",
    "\n",
    "# Define a backward hook to clip the gradients\n",
    "def clip_grads(module: nn.Module, \n",
    "               grad_in: t.Tuple[torch.Tensor, ...], \n",
    "               grad_out: t.Tuple[torch.Tensor, ...]):\n",
    "    gradient_threshold = 0.01\n",
    "    for grad in grad_in:\n",
    "        if grad is not None:\n",
    "            print(f'Backward input gradient -- shape: {grad.shape}')\n",
    "            clipped_grad = torch.clamp(grad, -gradient_threshold, gradient_threshold)\n",
    "            grad.copy_(clipped_grad)\n",
    "        else:\n",
    "            print('Backward input gradient -- Not a leaf node. Only leaf nodes accumulate gradients')\n",
    "    \n",
    "    # Output gradients\n",
    "    # For more information on how these are calculated, try reading up on autograd\n",
    "    # Essentially, we do a dot product with the transpose of the \n",
    "    # Jaocbian vector matrix x vector of gradients from a scalar function (think CE loss or MSE)\n",
    "    # Think of the second element in shape as the size of the previous layer (DL / D_theta_0, theta_1, ... theta_n) = \n",
    "    # Jacobian\n",
    "    for grad in grad_out:\n",
    "        if grad is not None:\n",
    "            print(f'Backward output gradient -- shape: {grad.shape}')\n",
    "        else:\n",
    "            print('Backward output gradient -- Not a leaf node. Only leaf nodes accumulate gradients')\n",
    "        \n",
    "\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    print(f'Forward: ouput_shape: {output[0].shape}')\n",
    "\n",
    "# Generate some input and target tensors for testing\n",
    "batch_size = 10\n",
    "input_tensor = torch.randn((batch_size, 10))\n",
    "target_tensor = torch.tensor([0, 1])\n",
    "target_tensor = target_tensor.repeat(5)  # repeat the target tensor to match the batch size\n",
    "\n",
    "# Initialize the model and loss function\n",
    "model = LinearModel()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Attach backward hooks to the linear layers\n",
    "model.fc_1.register_backward_hook(clip_grads)\n",
    "model.fc_2.register_backward_hook(clip_grads)\n",
    "model.fc_3.register_backward_hook(clip_grads)\n",
    "\n",
    "model.fc_1.register_forward_hook(forward_hook)\n",
    "model.fc_2.register_forward_hook(forward_hook)\n",
    "model.fc_3.register_forward_hook(forward_hook)\n",
    "\n",
    "# Forward pass\n",
    "output_tensor = model(input_tensor)\n",
    "loss = loss_function(output_tensor, target_tensor)\n",
    "\n",
    "# Backward pass\n",
    "model.zero_grad()\n",
    "# This will trigger all the backward hooks\n",
    "loss.backward()\n",
    "\n",
    "# Visualize the gradients\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].hist(model.fc_1.weight.grad.flatten())\n",
    "axs[0].set_title('fc_1 weight gradient')\n",
    "axs[1].hist(model.fc_2.weight.grad.flatten())\n",
    "axs[1].set_title('fc_2 weight gradient')\n",
    "axs[2].hist(model.fc_3.weight.grad.flatten())\n",
    "axs[2].set_title('fc_3 weight gradient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
